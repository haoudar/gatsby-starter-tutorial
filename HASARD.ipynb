{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOkoFhHs3hDkpEzmajsUbeL",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/haoudar/gatsby-starter-tutorial/blob/master/HASARD.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 86,
      "metadata": {
        "id": "w4XBKkTe7ULx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ff08858e-da1b-4232-e00d-4eb7c1ee7056"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   num0  num1  num2  num3  num4  num5  num6  num7\n",
            "0  18.0  19.0  31.0  33.0  35.0  40.0  50.0  16.0\n",
            "1   8.0  16.0  22.0  24.0  25.0  30.0  32.0  11.0\n",
            "2   2.0  12.0  22.0  30.0  32.0  35.0  36.0   1.0\n",
            "3   4.0  19.0  21.0  33.0  37.0  38.0  39.0  42.0\n",
            "4   7.0   8.0  18.0  26.0  33.0  42.0  46.0  39.0\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[16.0, 17.0, 31.0, 34.0, 36.0, 39.0, 41.0, 10.0],\n",
              " [4.0, 21.0, 23.0, 39.0, 40.0, 42.0, 50.0, 17.0]]"
            ]
          },
          "metadata": {},
          "execution_count": 86
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import pickle\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from tensorflow import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import LSTM, Dense, Bidirectional, TimeDistributed, RepeatVector, Flatten\n",
        "from keras.callbacks import EarlyStopping\n",
        "from keras import layers\n",
        "from io import StringIO\n",
        "import os\n",
        "\n",
        "data = StringIO(\n",
        "    \"\"\"\n",
        "9thMay2023 18 19 31 33 35 40 50 16\n",
        "5thMay2023 8 16 22 24 25 30 32 11\n",
        "2ndMay2023 2 12 22 30 32 35 36 1\n",
        "25thApril2023 4 19 21 33 37 38 39 42\n",
        "21thApril2023 7 8 18 26 33 42 46 39\n",
        "18thApril2023 5 7 16 20 26 30 36 44\n",
        "14thApril2023 17 25 28 30 34 46 49 42\n",
        "11thApril2023 4 5 11 12 31 43 44 15\n",
        "7thApril2023 15 26 34 41 44 45 46 11\n",
        "4thApril2023 6 15 29 32 36 45 48 39\n",
        "31thMarch2023 1 3 26 28 36 47 50 48\n",
        "28thMarch2023 5 9 12 19 21 22 49 31\n",
        "24thMarch2023 5 9 14 23 32 33 46 26\n",
        "21thMarch2023 7 15 17 20 32 40 50 21\n",
        "17thMarch2023 5 15 17 22 25 37 46 13\n",
        "14thMarch2023 4 15 17 24 27 32 41 36\n",
        "10thMarch2023 18 19 31 36 38 41 43 8\n",
        "7thMarsh2023 1 16 26 28 31 44 45 22\n",
        "3rdMarsh2023 10 14 20 37 42 44 46 50\n",
        "28thFebruary2023 1 3 8 24 35 42 43 18\n",
        "24thFebruary2023 1 11 15 21 35 48 49 3\n",
        "21thFebruary2023 2 14 26 31 35 39 49 32\n",
        "17thFebruary2023 10 12 23 26 39 41 45 42\n",
        "14thFebruary2023 9 15 21 28 31 36 38 12\n",
        "10thFebruary2023 6 16 22 23 28 29 34 8\n",
        "7thFebruary2023 1 13 26 30 37 42 50 10\n",
        "3rdFebruary2023 7 10 15 17 25 39 45 43\n",
        "31thJanuary2023 2 6 16 23 40 41 48 31\n",
        "27thJanuary2023 4 5 9 13 29 30 35 20\n",
        "24thJanuary2023 10 20 25 29 35 42 45 3\n",
        "20thJanuary2023 9 16 17 19 30 38 49 45\n",
        "17thJanuary2023 1 2 5 6 16 30 45 19\n",
        "13thJanuary2023 3 16 17 23 35 37 47 36\n",
        "10thJaunuary2023 10 16 18 33 34 37 45 36\n",
        "6thJanuary2023 7 14 20 24 35 40 50 15\n",
        "3rdJanuary2023 9 25 32 34 37 46 50 18\n",
        "30thDecember2022 6 26 32 37 38 39 46 7\n",
        "27thDecember2022 5 6 13 16 31 32 35 36\n",
        "23thDecember2022 7 17 20 22 31 36 48 34\n",
        "20thDecember2022 3 8 9 20 22 36 50 25\n",
        "16thDecember2022 6 22 25 42 43 45 48 47\n",
        "13thDecember2022 12 13 14 31 35 39 50 48\n",
        "9thDecember2022 2 18 20 22 34 43 48 7\n",
        "6thDecember2022 1 2 3 14 17 19 41 30\n",
        "2ndDecember2022 4 9 14 18 24 30 45 3\n",
        "27thNovember2022 1 7 8 19 32 38 39 49\n",
        "25thNovember2022 3 6 7 10 25 30 37 9\n",
        "22ndNovember2022 2 10 12 18 19 21 34 33\n",
        "18thNovember2022 3 5 11 17 26 42 49 27\n",
        "15thNovember2022 9 12 13 22 25 35 47 24\n",
        "11thNovember2022 5 23 34 35 46 47 50 10\n",
        "8thNovember2022 4 7 14 18 26 40 42 12\n",
        "4thNovember2022 4 8 25 27 32 33 34 16\n",
        "1stNovember2022 2 23 27 34 43 46 49 44\n",
        "28thOctober2022 12 17 29 30 38 40 50 16\n",
        "25thOctober2022 3 6 19 23 26 28 43 46\n",
        "21stOctober2022 1 9 25 35 41 43 50 40\n",
        "18thOctober2022 12 14 23 25 39 40 44 24\n",
        "14thOctober2022 2 24 27 31 40 43 46 13\n",
        "11thOctober2022 3 19 33 36 39 40 42 44\n",
        "7thOctober2022 7 23 28 31 32 39 40 2\n",
        "4thOctober2022 10 18 21 22 37 40 46 25\n",
        "30thSeptember2022 9 14 36 37 38 40 48 26\n",
        "27thSeptember2022 10 12 13 26 29 39 46 23\n",
        "23rdSeptember2022 15 17 21 24 28 32 43 27\n",
        "20thSeptember2022 9 10 11 20 24 31 48 36\n",
        "16thSeptember2022 2 13 24 34 39 40 46 23\n",
        "13thSeptember2022 9 10 14 32 35 36 46 47\n",
        "9thSeptember2022 1 2 15 18 29 32 36 9\n",
        "6thSeptember2022 16 22 28 30 41 46 47 10\n",
        "2ndSeptember2022 8 17 21 31 34 37 39 7\n",
        "30thAugust2022 5 8 12 23 39 41 48 50\n",
        "26thAugust2022 3 11 22 26 29 46 48 28\n",
        "23rdAugust2022 9 13 14 19 37 43 50 4\n",
        "19thAugust2022 5 20 26 33 35 46 48 17\n",
        "16thAugust2022 1 2 9 21 32 33 43 36\n",
        "12thAugust2022 4 10 28 36 40 44 47 19\n",
        "9thAugust2022 16 19 25 26 27 33 45 38\n",
        "5thAugust2022 7 16 19 33 36 48 49 5\n",
        "2ndAugust2022 4 5 15 18 22 28 32 19\n",
        "29thJuly2022 7 14 17 18 19 23 41 16\n",
        "26thJuly2022 3 8 9 15 21 27 31 33\n",
        "22ndJuly2022 1 9 19 34 37 39 49 6\n",
        "19thJuly2022 6 9 17 19 31 34 46 4\n",
        "15thJuly2022 4 7 12 18 29 47 49 48\n",
        "12thJuly2022 8 11 15 16 26 29 40 37\n",
        "8thJuly2022 7 12 14 18 46 47 49 19\n",
        "5thJuly2022 12 29 33 35 38 41 46 13\n",
        "1stJuly2022 1 11 13 14 25 36 47 50\n",
        "28thJune2022 8 19 22 41 42 46 47 10\n",
        "24thJune2022 3 9 17 19 20 44 50 28\n",
        "21stJune2022 2 4 5 22 32 40 50 43\n",
        "17thJune2022 1 10 12 21 30 39 40 38\n",
        "14thJune2022 11 17 18 25 36 41 50 34\n",
        "10thJune2022 8 14 16 17 19 22 24 23\n",
        "7thJune2022 6 13 17 20 28 36 44 31\n",
        "3rdJune2022 2 16 17 21 38 43 45 42\n",
        "31stMay2022 6 13 23 27 35 44 50 37\n",
        "27thMay2022 4 9 21 22 27 31 34 5\n",
        "24thMay2022 12 26 30 31 35 39 45 22\n",
        "20thMay2022 5 6 20 29 42 44 47 14\n",
        "17thMay2022 10 35 38 40 45 47 48 23\n",
        "13thMay2022 2 22 37 38 39 42 47 30\n",
        "10thMay2022 6 15 18 19 20 27 28 24\n",
        "6thMay2022 3 6 11 18 19 28 41 26\n",
        "3rdMay2022 6 11 22 24 27 29 33 31\n",
        "29thApril2022 8 9 19 32 37 46 48 45\n",
        "26thApril2022 3 10 15 31 35 38 42 22\n",
        "22ndApril2022 13 14 23 30 34 36 42 33\n",
        "19thApril2022 1 6 10 27 42 45 50 43\n",
        "15thApril2022 1 6 18 21 30 32 37 35\n",
        "12thApril2022 3 5 7 19 32 34 50 25\n",
        "8thApril2022 1 2 14 15 21 26 29 4\n",
        "5thApril2022 14 24 34 39 43 48 50 20\n",
        "1stApril2022 7 10 18 29 38 43 50 41\n",
        "29thMarch2022 7 17 32 34 39 45 47 42\n",
        "25thMarch2022 3 7 16 18 27 32 37 17\n",
        "22ndMarch2022 14 16 20 26 33 36 48 1\n",
        "18thMarch2022 5 7 12 18 26 29 46 25\n",
        "15thMarch2022 3 7 12 17 23 38 40 27\n",
        "11thMarch2022 5 7 12 22 28 43 47 1\n",
        "8thMarch2022 10 12 13 18 25 26 37 39\n",
        "4thMarch2022 2 4 14 18 24 46 47 23\n",
        "1stMarch2022 5 6 28 36 40 46 50 27\n",
        "25thFebruary2022 2 4 17 28 35 44 46 5\n",
        "22ndFebruary2022 3 13 26 27 28 36 45 50\n",
        "18thFebruary2022 2 3 8 11 12 37 49 36\n",
        "15thFebruary2022 19 26 28 36 40 42 48 6\n",
        "11thFebruary2022 1 10 12 30 33 34 36 4\n",
        "8thFebruary2022 16 29 32 34 38 39 47 18\n",
        "4thFebruary2022 5 15 19 22 37 46 47 1\n",
        "1stFebruary2022 9 14 24 26 29 39 49 42\n",
        "28thJanuary2022 3 7 8 10 34 43 47 16\n",
        "25thJanuary2022 11 13 18 20 23 30 40 37\n",
        "21stJanuary2022 10 14 21 26 28 36 50 41\n",
        "18thJanuary2022 2 15 25 28 30 35 38 31\n",
        "14thJanuary2022 2 4 7 10 14 21 34 26\n",
        "11thJanuary2022 1 3 24 25 27 36 47 12\n",
        "7thJanuary2022 4 5 31 39 42 45 50 11\n",
        "4thJanuary2022 7 8 13 20 25 26 48 36\n",
        "31stDecember2021 7 25 30 35 38 40 49 27\n",
        "28thDecember2021 11 12 21 27 32 43 49 15\n",
        "24thDecember2021 3 11 24 25 29 32 42 16\n",
        "21stDecember2021 13 23 26 27 28 38 47 36\n",
        "17thDecember2021 9 14 16 33 39 46 49 38\n",
        "14thDecember2021 3 21 22 26 28 44 49 34\n",
        "10thDecember2021 17 21 27 32 45 46 49 19\n",
        "7thDecember2021 9 16 19 24 27 34 40 7\n",
        "3rdDecember2021 7 18 22 35 37 43 45 44\n",
        "30thNovember2021 4 7 8 22 24 30 49 42\n",
        "26thNovember2021 9 26 30 35 37 42 50 47\n",
        "23rdNovember2021 14 17 25 27 31 32 34 20\n",
        "19thNovember2021 1 13 14 17 25 28 41 43\n",
        "16thNovember2021 5 6 7 17 26 29 42 38\n",
        "12thNovember2021 4 6 7 10 17 27 44 40\n",
        "9thNovember2021 2 8 16 17 19 26 42 41\n",
        "5thNovember2021 2 10 11 17 19 32 42 41\n",
        "2ndNovember2021 7 13 18 30 33 37 41 6\n",
        "29thOctober2021 1 5 17 18 38 41 48 13\n",
        "26thOctober2021 2 8 10 14 21 36 40 17\n",
        "22ndOctober2021 2 11 19 33 44 45 47 42\n",
        "19thOctober2021 12 26 28 32 41 43 50 49\n",
        "15thOctober2021 14 17 20 24 25 38 48 11\n",
        "12thOctober2021 7 11 13 30 38 40 43 45\n",
        "8thOctober2021 5 16 19 21 23 31 36 46\n",
        "5thOctober2021 2 10 18 19 25 42 48 21\n",
        "1stOctober2021 4 8 15 39 40 42 48 5\n",
        "28thSeptember2021 2 5 8 18 23 31 35 43\n",
        "24thSeptember2021 5 13 28 35 41 49 50 34\n",
        "21stSeptember2021 4 8 11 14 15 34 45 7\n",
        "17thSeptember2021 3 6 10 26 29 35 45 30\n",
        "14thSeptember2021 17 24 27 33 38 41 48 39\n",
        "10thSeptember2021 11 28 38 40 43 45 48 33\n",
        "7thSeptember2021 5 8 31 36 41 42 43 39\n",
        "3rdSeptember2021 1 2 4 10 27 33 45 31\n",
        "31stAugust2021 3 11 23 26 31 42 50 24\n",
        "27thAugust2021 9 10 13 25 41 47 49 36\n",
        "24thAugust2021 1 24 26 29 30 45 50 5\n",
        "20thAugust2021 2 6 21 31 34 39 45 33\n",
        "17thAugust2021 5 16 18 33 37 38 39 35\n",
        "13thAugust2021 1 14 17 20 28 32 38 6\n",
        "10thAugust2021 14 18 19 32 35 38 41 27\n",
        "6thAugust2021 14 15 24 43 44 48 49 47\n",
        "3rdAugust2021 4 5 9 15 24 36 48 50\n",
        "30thJuly2021 4 12 18 19 22 25 44 43\n",
        "27thJuly2021 5 12 13 32 36 40 48 49\n",
        "23rdJuly2021 7 8 13 21 35 38 45 15\n",
        "20thJuly2021 2 13 15 19 38 39 46 34\n",
        "16thJuly2021 13 17 24 26 33 46 48 27\n",
        "13thJuly2021 2 6 12 13 17 36 48 25\n",
        "9thJuly2021 11 21 32 33 38 40 44 19\n",
        "6thJuly2021 10 14 25 26 38 41 50 49\n",
        "2ndJuly2021 6 14 35 37 40 43 46 19\n",
        "29thJune2021 6 17 22 23 32 37 47 13\n",
        "25thJune2021 10 13 18 33 36 45 47 22\n",
        "22ndJune2021 7 11 22 28 33 44 49 10\n",
        "18thJune2021 11 14 15 24 34 43 47 36\n",
        "15thJune2021 2 8 12 13 14 36 43 29\n",
        "11thJune2021 20 21 25 33 38 44 45 22\n",
        "8thJune2021 1 9 14 24 26 37 42 29\n",
        "4thJune2021 2 3 16 28 31 42 47 12\n",
        "1stJune2021 6 20 21 28 38 43 47 40\n",
        "28thMay2021 7 18 22 40 44 46 50 5\n",
        "25thMay2021 6 9 11 19 24 38 46 18\n",
        "21stMay2021 5 6 25 31 32 44 48 39\n",
        "18thMay2021 5 9 18 27 32 38 40 34\n",
        "14thMay2021 3 18 19 24 26 27 45 20\n",
        "11thMay2021 14 15 20 32 35 38 50 46\n",
        "7thMay2021 1 8 17 21 35 39 46 31\n",
        "4thMay2021 1 23 27 33 39 45 49 40\n",
        "30thApril2021 2 14 27 30 31 35 43 38\n",
        "27thApril2021 7 11 14 26 27 29 36 2\n",
        "23rdApril2021 1 3 4 11 19 24 42 27\n",
        "20thApril2021 7 10 11 19 22 30 37 18\n",
        "16thApril2021 1 13 19 27 42 49 50 32\n",
        "13thApril2021 15 16 18 19 22 44 47 28\n",
        "9thApril2021 1 19 28 29 31 33 43 17\n",
        "6thApril2021 2 14 24 25 35 44 45 11\n",
        "2ndApril2021 30 32 33 34 37 45 49 25\n",
        "30thMarch2021 12 22 25 30 37 38 45 2\n",
        "26thMarch2021 2 4 16 24 25 27 49 29\n",
        "23rdMarch2021 5 6 12 28 29 36 46 40\n",
        "19thMarch2021 2 7 8 26 30 43 48 25\n",
        "16thMarch2021 8 15 25 27 33 39 44 20\n",
        "12thMarch2021 5 12 15 23 28 38 39 46\n",
        "9thMarch2021 3 7 16 22 29 31 42 15\n",
        "5thMarch2021 6 9 23 25 31 36 48 30\n",
        "2ndMarch2021 9 29 30 36 42 46 49 47\n",
        "26thFebruary2021 11 17 19 22 27 31 40 38\n",
        "23rdFebruary2021 3 13 14 20 30 45 49 35\n",
        "19thFebruary2021 1 5 10 18 20 40 42 47\n",
        "16thFebruary2021 1 6 12 21 34 37 47 20\n",
        "12thFebruary2021 2 5 10 11 14 23 33 47\n",
        "9thFebruary2021 4 12 16 17 33 36 44 2\n",
        "5thFebruary2021 1 2 23 32 35 36 45 28\n",
        "2ndFebruary2021 17 24 27 34 38 42 48 19\n",
        "29thJanuary2021 9 11 20 22 33 36 46 49\n",
        "26thJanuary2021 26 37 42 44 46 49 50 24\n",
        "22ndJanuary2021 11 21 23 25 28 41 43 10\n",
        "19thJanuary2021 23 31 34 38 40 45 50 41\n",
        "15thJanuary2021 5 23 31 35 36 37 43 13\n",
        "12thJanuary2021 4 12 13 15 18 30 50 34\n",
        "8thJanuary2021 4 21 24 25 26 27 42 8\n",
        "5thJanuary2021 1 16 21 24 35 37 39 45\n",
        "1stJanuary2021 18 21 28 29 31 32 49 38\n",
        "29thDecember2020 8 12 23 25 29 43 46 13\n",
        "25thDecember2020 8 12 16 30 38 48 50 14\n",
        "22ndDecember2020 4 29 30 37 38 43 44 15\n",
        "18thDecember2020 2 9 10 22 31 35 49 30\n",
        "15thDecember2020 1 4 20 33 44 45 49 47\n",
        "11thDecember2020 9 21 30 33 38 39 46 48\n",
        "8thDecember2020 5 13 14 21 36 37 43 40\n",
        "4thDecember2020 5 7 14 23 24 46 47 11\n",
        "1stDecember2020 1 4 9 15 18 24 31 43\n",
        "27thNovember2020 9 15 35 41 42 45 46 43\n",
        "24thNovember2020 6 8 13 27 41 46 47 39\n",
        "20thNovember2020 11 17 29 33 39 40 42 48\n",
        "17thNovember2020 6 18 21 30 31 34 38 1\n",
        "13thNovember2020 3 4 7 19 44 48 49 8\n",
        "10thNovember2020 4 6 18 27 28 30 40 13\n",
        "6thNovember2020 7 9 19 20 26 32 35 49\n",
        "3rdNovember2020 5 7 14 21 26 34 49 31\n",
        "30thOctober2020 19 20 23 31 37 46 48 50\n",
        "27thOctober2020 2 9 11 29 33 39 44 15\n",
        "23rdOctober2020 2 8 20 21 29 34 37 41\n",
        "20thOctober2020 8 27 30 44 46 47 50 32\n",
        "16thOctober2020 1 4 8 10 12 17 41 19\n",
        "13thOctober2020 3 10 13 19 21 45 49 12\n",
        "9thOctober2020 4 6 12 30 32 33 34 29\n",
        "6thOctober2020 4 5 9 19 28 34 44 8\n",
        "2ndOctober2020 7 12 16 26 40 45 49 20\n",
        "29thSeptember2020 4 6 9 15 22 24 28 44\n",
        "25thSeptember2020 1 7 9 28 38 48 50 13\n",
        "22ndSeptember2020 8 9 37 38 40 43 49 28\n",
        "18thSeptember2020 2 11 22 25 32 40 44 27\n",
        "15thSeptember2020 1 5 6 24 27 28 32 38\n",
        "11thSeptember2020 4 15 16 17 35 46 50 13\n",
        "8thSeptember2020 6 12 19 27 30 32 44 18\n",
        "4thSeptember2020 7 18 22 26 35 41 50 11\n",
        "1stSeptember2020 2 9 29 30 31 35 37 19\n",
        "28thAugust2020 5 8 9 28 32 48 50 40\n",
        "25thAugust2020 1 21 34 38 39 40 46 24\n",
        "21stAugust2020 1 2 5 11 20 30 39 27\n",
        "18thAugust2020 1 2 16 32 44 46 50 6\n",
        "14thAugust2020 3 22 37 39 41 43 44 20\n",
        "11thAugust2020 9 17 22 33 36 45 46 41\n",
        "7thAugust2020 9 21 26 28 30 37 44 31\n",
        "4thAugust2020 18 24 25 30 31 33 48 27\n",
        "31stJuly2020 8 16 19 22 28 31 38 25\n",
        "28thJuly2020 7 10 11 24 39 43 48 23\n",
        "24thJuly2020 17 20 27 29 37 39 41 10\n",
        "21stJuly2020 7 22 26 35 46 47 49 19\n",
        "17thJuly2020 5 11 15 18 20 24 46 37\n",
        "14thJuly2020 3 9 21 35 44 47 48 23\n",
        "10thJuly2020 17 18 27 38 39 40 47 24\n",
        "7thJuly2020 9 20 21 22 25 26 37 3\n",
        "3rdJuly2020 3 4 21 33 38 44 45 32\n",
        "30thJune2020 11 12 22 33 37 48 49 41\n",
        "26thJune2020 8 14 31 36 39 46 47 20\n",
        "23rdJune2020 2 3 6 13 37 42 46 19\n",
        "19thJune2020 3 12 17 22 29 31 48 8\n",
        "16thJune2020 1 3 22 30 31 37 40 6\n",
        "12thJune2020 1 16 24 28 30 31 47 25\n",
        "5thJune2020 1 8 15 16 32 39 40 31\n",
        "29thMay2020 5 12 15 23 26 38 41 45\n",
        "22ndMay2020 9 11 14 21 22 24 41 10\n",
        "15thMay2020 7 30 32 40 47 48 50 16\n",
        "8thMay2020 3 4 10 11 26 28 40 31\n",
        "1stMay2020 3 12 25 36 37 42 49 9\n",
        "24thApril2020 8 9 19 26 27 31 46 48\n",
        "17thApril2020 2 15 21 29 40 47 50 35\n",
        "10thApril2020 3 9 10 14 15 19 20 25\n",
        "3rdApril2020 5 9 10 25 27 29 38 31\n",
        "31stMarch2020 5 7 22 29 32 37 39 3\n",
        "20thMarch2020 9 16 17 18 21 22 27 31\n",
        "13thMarch2020 7 14 15 35 36 49 50 11\n",
        "6thMarch2020 2 9 10 35 41 42 47 40\n",
        "28thFebruary2020 21 27 30 32 33 36 46 38\n",
        "21stFebruary2020 4 7 14 37 48 49 50 28\n",
        "14thFebruary2020 14 17 20 34 38 45 49 5\n",
        "7thFebruary2020 21 24 26 31 36 48 49 39\n",
        "31stJanuary2020 2 27 30 39 44 45 49 17\n",
        "24thJanuary2020 2 11 14 21 23 34 36 5\n",
        "17thJanuary2020 5 6 36 39 40 46 48 34\n",
        "10thJanuary2020 10 13 14 24 28 47 48 12\n",
        "3rdJanuary2020 8 18 20 24 31 37 39 34\n",
        "27thDecember2019 13 27 34 36 38 45 50 18\n",
        "20thDecember2019 14 23 28 29 30 33 48 9\n",
        "13thDecember2019 2 12 14 15 26 34 39 48\n",
        "6thDecember2019 9 11 17 19 35 36 43 28\n",
        "29thNovember2019 3 8 14 15 24 33 48 4\n",
        "22ndNovember2019 5 9 23 29 30 31 37 34\n",
        "15thNovember2019 15 16 33 36 38 43 49 4\n",
        "8thNovember2019 3 5 10 18 26 33 46 49\n",
        "1stNovember2019 10 20 24 25 32 39 46 15\n",
        "25thOctober2019 6 11 16 18 23 26 40 45\n",
        "18thOctober2019 3 21 29 37 40 43 44 38\n",
        "11thOctober2019 1 3 11 13 19 22 46 31\n",
        "4thOctober2019 20 31 35 36 39 42 44 23\n",
        "27thSeptember2019 3 9 25 26 28 34 38 36\n",
        "20thSeptember2019 9 15 26 36 39 41 47 37\n",
        "13thSeptember2019 4 16 21 32 44 45 50 26\n",
        "6thSeptember2019 4 5 24 25 43 44 50 41\n",
        "30thAugust2019 5 9 33 36 39 41 44 27\n",
        "23rdAugust2019 5 6 8 15 22 46 47 31\n",
        "16thAugust2019 22 24 25 26 29 32 46 20\n",
        "9thAugust2019 10 25 31 34 36 39 45 9\n",
        "2ndAugust2019 11 20 23 24 26 41 44 38\n",
        "26thJuly2019 11 15 17 20 24 25 50 30\n",
        "19thJuly2019 1 15 21 29 30 31 33 5\n",
        "12thJuly2019 3 13 19 25 28 30 37 1\n",
        "5thJuly2019 1 4 8 28 32 36 43 40\n",
        "28thJune2019 7 11 36 37 38 43 46 26\n",
        "21stJune2019 11 16 17 20 42 44 50 31\n",
        "14thJune2019 4 11 20 22 37 44 49 13\n",
        "7thJune2019 4 8 13 23 25 33 39 17\n",
        "31stMay2019 6 29 34 39 42 47 50 22\n",
        "24thMay2019 9 11 15 19 20 35 41 28\n",
        "17thMay2019 4 21 23 39 40 42 50 17\n",
        "10thMay2019 16 17 31 34 36 39 41 10\n",
        "    \"\"\"\n",
        ")\n",
        "\n",
        "#num'x' represent the drawn number in column x\n",
        "\n",
        "dt = np.genfromtxt(\n",
        "    data,\n",
        "    names=\"date, num0, num1, num2, num3, num4, num5, num6, num7\",\n",
        "    usecols=(\"num0\", \"num1\", \"num2\", \"num3\", \"num4\", \"num5\", \"num6\", \"num7\"),\n",
        "    comments=\"#\",\n",
        ")\n",
        "\n",
        "dict_tirages = {}\n",
        "chiff = 'num'\n",
        "for i in range(0, 8):\n",
        "  x = \"{}{}\".format(chiff, i)\n",
        "  dict_tirages[x] = dt[x]\n",
        "\n",
        "df_tirages = pd.DataFrame.from_dict(data=dict_tirages)\n",
        "print(df_tirages.head())\n",
        "#inversion du dataframe pour placer le dernier tirage en dernière position\n",
        "df = df_tirages.iloc[::-1]\n",
        "df.values.tolist()[0:2]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#fonction de vérification de nombres en dessous d'une certaine valeur pour les numéros.\n",
        "def is_under(data, number):\n",
        "    return ((data['num0'].isin(number)).astype(int) + \n",
        "            (data['num1'].isin(number)).astype(int) +\n",
        "            (data['num2'].isin(number)).astype(int) +\n",
        "            (data['num3'].isin(number)).astype(int) +\n",
        "            (data['num4'].isin(number)).astype(int) +\n",
        "            (data['num5'].isin(number)).astype(int) +\n",
        "            (data['num6'].isin(number)).astype(int) +\n",
        "            (data['num7'].isin(number)).astype(int)\n",
        "            )\n",
        "\n",
        "#fonction de vérification de nombres pairs pour les 5 premiers numéros sauf celui de chance\n",
        "def is_pair(data):\n",
        "    return ((data['num0'].isin(pairs)).astype(int) + \n",
        "            (data['num1'].isin(pairs)).astype(int) +\n",
        "            (data['num2'].isin(pairs)).astype(int) +\n",
        "            (data['num3'].isin(pairs)).astype(int) +\n",
        "            (data['num4'].isin(pairs)).astype(int) +\n",
        "            (data['num5'].isin(pairs)).astype(int) +\n",
        "            (data['num6'].isin(pairs)).astype(int) +\n",
        "            (data['num7'].isin(pairs)).astype(int)\n",
        "            )\n",
        "\n",
        "#fonction de vérification de nombres impairs pour les 5 premiers numéros sauf celui de chance\n",
        "def is_impair(data):\n",
        "    return ((data['num0'].isin(impairs)).astype(int) + \n",
        "            (data['num1'].isin(impairs)).astype(int) +\n",
        "            (data['num2'].isin(impairs)).astype(int) +\n",
        "            (data['num3'].isin(impairs)).astype(int) +\n",
        "            (data['num4'].isin(impairs)).astype(int) +\n",
        "            (data['num5'].isin(impairs)).astype(int) +\n",
        "            (data['num6'].isin(impairs)).astype(int) +\n",
        "            (data['num7'].isin(impairs)).astype(int)\n",
        "            )\n",
        "\n",
        "\n",
        "#liste de nombres pairs et impairs\n",
        "pairs = np.arange(2, 51, 2) \n",
        "impairs = np.arange(1, 50, 2) \n",
        "\n",
        "#liste de partitions\n",
        "UN = np.arange(1, 11)\n",
        "DZ = np.arange(11, 21)\n",
        "VT = np.arange(21, 31)\n",
        "TR = np.arange(31, 41)\n",
        "QR = np.arange(41, 51)\n",
        "\n",
        "#Fonction de calcul de la somme de la différence au carré des numéros.\n",
        "def sum_diff(data):\n",
        "    return ((data['num1'] - data['num0'])**2 + \n",
        "            (data['num2'] - data['num0'])**2 +\n",
        "            (data['num3'] - data['num0'])**2 +\n",
        "            (data['num4'] - data['num0'])**2 +\n",
        "            (data['num5'] - data['num0'])**2 +\n",
        "            (data['num6'] - data['num0'])**2 +\n",
        "            (data['num7'] - data['num0'])**2\n",
        "            )\n",
        "\n",
        "\n",
        "# Calcul de la fréquence de tirage de chaque numéro\n",
        "def freq_val(data, column):\n",
        "    tab = data[column].values.tolist()\n",
        "    freqs = []\n",
        "    pos = 1\n",
        "    for e in tab:\n",
        "        freqs.append(tab[0:pos].count(e))\n",
        "        pos = pos + 1\n",
        "    return freqs\n",
        "\n",
        "    \n",
        "\n",
        "\n",
        "\n",
        "#df['sum'] = ((df.num0 + df.num1 + df.num2 + df.num3 + df.num4 + df.chance ) >185).astype(int)"
      ],
      "metadata": {
        "id": "M71X-tr_B5So"
      },
      "execution_count": 87,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#ajout de la difference entre les numéros(A explorer ASAp)\n",
        "#for i in range(4):\n",
        "    #print(i,i+1)\n",
        "    #df['diff_{}'.format(i)]=df['num{}'.format(i+1)]-df['num{}'.format(i)]\n",
        "#application des fonctions sur le dataframe\n",
        "df['freq_num0'] = freq_val(df,'num0')\n",
        "df['freq_num1'] = freq_val(df,\"num1\")\n",
        "df['freq_num2'] = freq_val(df, \"num2\")\n",
        "df['freq_num3'] = freq_val(df, \"num3\")\n",
        "df['freq_num4'] = freq_val(df, \"num4\")\n",
        "df['freq_num5'] = freq_val(df, \"num5\")\n",
        "df['freq_num6'] = freq_val(df, \"num6\")\n",
        "df['freq_num7'] = freq_val(df, \"num7\")\n",
        "df['sum_diff'] = sum_diff(df)#somme de la différence au carré entre chaque couple de numéros successifs dans le tirage\n",
        "df['pair'] = is_pair(df)\n",
        "df['impair'] = is_impair(df)#verification de nombre pair et impair\n",
        "df['is_under_11'] = is_under(df, UN)  # Les numeros en dessous de 11 \n",
        "df['is_under_21'] = is_under(df, DZ)# Les numeros en dessous de 21 \n",
        "df['is_under_31'] = is_under(df, VT)# Les numeros en dessous de 31 \n",
        "df['is_under_41'] = is_under(df, TR)# Les numeros en dessous de 41 \n",
        "df['is_under_51'] = is_under(df, QR)# Les numeros en dessous de 51 \n",
        "df.head()"
      ],
      "metadata": {
        "id": "GeXeDkrSE1gq",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "7d161e31-2db2-42f4-89e9-1346eb5e2c57"
      },
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-88-67636cbf89df>:6: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df['freq_num0'] = freq_val(df,'num0')\n",
            "<ipython-input-88-67636cbf89df>:7: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df['freq_num1'] = freq_val(df,\"num1\")\n",
            "<ipython-input-88-67636cbf89df>:8: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df['freq_num2'] = freq_val(df, \"num2\")\n",
            "<ipython-input-88-67636cbf89df>:9: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df['freq_num3'] = freq_val(df, \"num3\")\n",
            "<ipython-input-88-67636cbf89df>:10: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df['freq_num4'] = freq_val(df, \"num4\")\n",
            "<ipython-input-88-67636cbf89df>:11: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df['freq_num5'] = freq_val(df, \"num5\")\n",
            "<ipython-input-88-67636cbf89df>:12: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df['freq_num6'] = freq_val(df, \"num6\")\n",
            "<ipython-input-88-67636cbf89df>:13: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df['freq_num7'] = freq_val(df, \"num7\")\n",
            "<ipython-input-88-67636cbf89df>:14: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df['sum_diff'] = sum_diff(df)#somme de la différence au carré entre chaque couple de numéros successifs dans le tirage\n",
            "<ipython-input-88-67636cbf89df>:15: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df['pair'] = is_pair(df)\n",
            "<ipython-input-88-67636cbf89df>:16: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df['impair'] = is_impair(df)#verification de nombre pair et impair\n",
            "<ipython-input-88-67636cbf89df>:17: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df['is_under_11'] = is_under(df, UN)  # Les numeros en dessous de 11\n",
            "<ipython-input-88-67636cbf89df>:18: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df['is_under_21'] = is_under(df, DZ)# Les numeros en dessous de 21\n",
            "<ipython-input-88-67636cbf89df>:19: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df['is_under_31'] = is_under(df, VT)# Les numeros en dessous de 31\n",
            "<ipython-input-88-67636cbf89df>:20: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df['is_under_41'] = is_under(df, TR)# Les numeros en dessous de 41\n",
            "<ipython-input-88-67636cbf89df>:21: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df['is_under_51'] = is_under(df, QR)# Les numeros en dessous de 51\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     num0  num1  num2  num3  num4  num5  num6  num7  freq_num0  freq_num1  \\\n",
              "359  16.0  17.0  31.0  34.0  36.0  39.0  41.0  10.0          1          1   \n",
              "358   4.0  21.0  23.0  39.0  40.0  42.0  50.0  17.0          1          1   \n",
              "357   9.0  11.0  15.0  19.0  20.0  35.0  41.0  28.0          1          1   \n",
              "356   6.0  29.0  34.0  39.0  42.0  47.0  50.0  22.0          1          1   \n",
              "355   4.0   8.0  13.0  23.0  25.0  33.0  39.0  17.0          2          1   \n",
              "\n",
              "     ...  freq_num6  freq_num7  sum_diff  pair  impair  is_under_11  \\\n",
              "359  ...          1          1    2140.0     4       4            1   \n",
              "358  ...          1          1    6900.0     4       4            1   \n",
              "357  ...          2          1    2322.0     2       6            1   \n",
              "356  ...          2          1    7571.0     5       3            1   \n",
              "355  ...          1          2    3134.0     2       6            2   \n",
              "\n",
              "     is_under_21  is_under_31  is_under_41  is_under_51  \n",
              "359            2            0            4            1  \n",
              "358            1            2            2            2  \n",
              "357            4            1            1            1  \n",
              "356            0            2            2            3  \n",
              "355            2            2            2            0  \n",
              "\n",
              "[5 rows x 24 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-439e0831-a55c-4811-b858-6e5cefcf5189\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>num0</th>\n",
              "      <th>num1</th>\n",
              "      <th>num2</th>\n",
              "      <th>num3</th>\n",
              "      <th>num4</th>\n",
              "      <th>num5</th>\n",
              "      <th>num6</th>\n",
              "      <th>num7</th>\n",
              "      <th>freq_num0</th>\n",
              "      <th>freq_num1</th>\n",
              "      <th>...</th>\n",
              "      <th>freq_num6</th>\n",
              "      <th>freq_num7</th>\n",
              "      <th>sum_diff</th>\n",
              "      <th>pair</th>\n",
              "      <th>impair</th>\n",
              "      <th>is_under_11</th>\n",
              "      <th>is_under_21</th>\n",
              "      <th>is_under_31</th>\n",
              "      <th>is_under_41</th>\n",
              "      <th>is_under_51</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>359</th>\n",
              "      <td>16.0</td>\n",
              "      <td>17.0</td>\n",
              "      <td>31.0</td>\n",
              "      <td>34.0</td>\n",
              "      <td>36.0</td>\n",
              "      <td>39.0</td>\n",
              "      <td>41.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2140.0</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>358</th>\n",
              "      <td>4.0</td>\n",
              "      <td>21.0</td>\n",
              "      <td>23.0</td>\n",
              "      <td>39.0</td>\n",
              "      <td>40.0</td>\n",
              "      <td>42.0</td>\n",
              "      <td>50.0</td>\n",
              "      <td>17.0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>6900.0</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>357</th>\n",
              "      <td>9.0</td>\n",
              "      <td>11.0</td>\n",
              "      <td>15.0</td>\n",
              "      <td>19.0</td>\n",
              "      <td>20.0</td>\n",
              "      <td>35.0</td>\n",
              "      <td>41.0</td>\n",
              "      <td>28.0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>2322.0</td>\n",
              "      <td>2</td>\n",
              "      <td>6</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>356</th>\n",
              "      <td>6.0</td>\n",
              "      <td>29.0</td>\n",
              "      <td>34.0</td>\n",
              "      <td>39.0</td>\n",
              "      <td>42.0</td>\n",
              "      <td>47.0</td>\n",
              "      <td>50.0</td>\n",
              "      <td>22.0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>7571.0</td>\n",
              "      <td>5</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>355</th>\n",
              "      <td>4.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>13.0</td>\n",
              "      <td>23.0</td>\n",
              "      <td>25.0</td>\n",
              "      <td>33.0</td>\n",
              "      <td>39.0</td>\n",
              "      <td>17.0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>3134.0</td>\n",
              "      <td>2</td>\n",
              "      <td>6</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 24 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-439e0831-a55c-4811-b858-6e5cefcf5189')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-439e0831-a55c-4811-b858-6e5cefcf5189 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-439e0831-a55c-4811-b858-6e5cefcf5189');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 88
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# j'ai ici défini plusieurs modèles à tester mais pour l'intant je tavaille avec le lstm(fonction : define_model)\n",
        "# j'ai ici défini window_length à 12 pour apprendre sur 1 mois de données \n",
        "\n",
        "#Params du modèle\n",
        "nb_label_feature=8\n",
        "\n",
        "UNITS = 128\n",
        "BATCHSIZE = 24\n",
        "EPOCH = 600\n",
        "#ACTIVATION = \"softmax\"\n",
        "OPTIMIZER ='adam' # rmsprop, adam, sgd\n",
        "LOSS = 'mae'#'categorical_crossentropy' #mse\n",
        "DROPOUT = 0.1\n",
        "window_length = 12 #12 \n",
        "number_of_features = df.shape[1]\n",
        "\n",
        "#Architecture du modèle\n",
        "def define_model(number_of_features,nb_label_feature):\n",
        "    #initialisation du rnn\n",
        "    model = Sequential()\n",
        "    #ajout de la premiere couche lstm\n",
        "    model.add(LSTM(UNITS, input_shape=(window_length, number_of_features), return_sequences=True))\n",
        "    model.add(LSTM(UNITS, dropout=0.1, return_sequences=True))\n",
        "    model.add(LSTM(UNITS, dropout=0.0, return_sequences=False))\n",
        "    #ajout de la couche de sortie\n",
        "    model.add(Dense(nb_label_feature))\n",
        "    model.compile(loss=LOSS, optimizer=OPTIMIZER, metrics=['acc'])\n",
        "    return model\n",
        "\n",
        "def define_bidirectionnel_model(number_of_features,nb_label_feature):\n",
        "    model = Sequential()\n",
        "    model.add(Bidirectional(LSTM(100, dropout=0.2, return_sequences=True), input_shape=(window_length, number_of_features)))\n",
        "    model.add(LSTM(50, return_sequences=True))\n",
        "    model.add(LSTM(100, dropout=0.1))\n",
        "    model.add(Dense(nb_label_feature))\n",
        "    model.compile(loss=LOSS, optimizer=OPTIMIZER, metrics=['acc'])\n",
        "    return model\n",
        "\n",
        "def define_autoencoder_model(number_of_features,nb_label_feature):\n",
        "    model = Sequential()\n",
        "    model.add(LSTM(100, input_shape=(window_length, number_of_features), return_sequences=True))\n",
        "    model.add(LSTM(50, return_sequences=False))\n",
        "    model.add(RepeatVector(window_length))\n",
        "    model.add(LSTM(100, dropout=0.1, return_sequences=True))\n",
        "    model.add(LSTM(50, return_sequences=True))\n",
        "    model.add(TimeDistributed(Dense(number_of_features)))\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(nb_label_feature))\n",
        "    model.compile(loss=LOSS, optimizer=OPTIMIZER, metrics=['acc'])\n",
        "    return model\n",
        "\n",
        "\n",
        "\n",
        "#model = define_model(number_of_features,nb_label_feature)\n",
        "#model3 = define_autoencoder_model(number_of_features,nb_label_feature)\n",
        "#model4 = define_bidirectionnel_model(number_of_features,nb_label_feature)\n",
        "\n",
        "#Moniteur pour stoper le training\n",
        "es = EarlyStopping(monitor='acc', mode='max', verbose=1, patience=100, min_delta=0.001)"
      ],
      "metadata": {
        "id": "Om_YpN_2HmDU"
      },
      "execution_count": 89,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Fonction de formatage des données en entrée du LSTM\n",
        "def create_lstm_dataset(df, window_length,nb_label_feature):\n",
        "    number_of_rows = df.shape[0]   #taille du dataset number_of_features\n",
        "    number_of_features = df.shape[1]\n",
        "    scaler = StandardScaler().fit(df.values)\n",
        "    transformed_dataset = scaler.transform(df.values)\n",
        "    transformed_df = pd.DataFrame(data=transformed_dataset, index=df.index)\n",
        "    #tableau de tableau de taille(number_of_rows-window_length) et window_length ligne,number_of_features\n",
        "    #lstm:[nb total de row ,nb de ligne dans le passé, nb de colonne(feature)]\n",
        "    train = np.empty([number_of_rows-window_length, window_length, number_of_features], dtype=float)\n",
        "    \n",
        "    label = np.empty([number_of_rows-window_length, nb_label_feature], dtype=float)\n",
        "    for i in range(0, number_of_rows-window_length):\n",
        "        train[i] = transformed_df.iloc[i:i+window_length, 0: number_of_features]\n",
        "        label[i] = transformed_df.iloc[i+window_length: i+window_length+1, 0:nb_label_feature]\n",
        "        \n",
        "    #définition du modèle Lstm  \n",
        "    model = define_model(number_of_features,nb_label_feature)\n",
        "    #model = define_bidirectionnel_model(number_of_features,nb_label_feature)\n",
        "         \n",
        "    return train, label, model,scaler\n"
      ],
      "metadata": {
        "id": "NRv0CnZiIKAO"
      },
      "execution_count": 90,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#formatage des données\n",
        "train, label,model,scaler1 = create_lstm_dataset(df, window_length,nb_label_feature)\n",
        "print(train.shape)\n",
        "print(label.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ypPw-5_kIPc6",
        "outputId": "47929c7d-0472-43cd-bb76-060bde450451"
      },
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(348, 12, 24)\n",
            "(348, 8)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "history=model.fit(train, label, batch_size=BATCHSIZE, epochs=EPOCH, verbose=2, callbacks=[es])"
      ],
      "metadata": {
        "id": "qAZOg4ysI-OB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "208feb9a-dd94-4d86-abba-1c241c45ed49"
      },
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/600\n",
            "15/15 - 7s - loss: 0.8185 - acc: 0.1207 - 7s/epoch - 447ms/step\n",
            "Epoch 2/600\n",
            "15/15 - 1s - loss: 0.8015 - acc: 0.1063 - 669ms/epoch - 45ms/step\n",
            "Epoch 3/600\n",
            "15/15 - 1s - loss: 0.7949 - acc: 0.1207 - 664ms/epoch - 44ms/step\n",
            "Epoch 4/600\n",
            "15/15 - 1s - loss: 0.7869 - acc: 0.1782 - 674ms/epoch - 45ms/step\n",
            "Epoch 5/600\n",
            "15/15 - 1s - loss: 0.7843 - acc: 0.1868 - 670ms/epoch - 45ms/step\n",
            "Epoch 6/600\n",
            "15/15 - 1s - loss: 0.7777 - acc: 0.1580 - 657ms/epoch - 44ms/step\n",
            "Epoch 7/600\n",
            "15/15 - 1s - loss: 0.7635 - acc: 0.2098 - 977ms/epoch - 65ms/step\n",
            "Epoch 8/600\n",
            "15/15 - 1s - loss: 0.7554 - acc: 0.2270 - 1s/epoch - 77ms/step\n",
            "Epoch 9/600\n",
            "15/15 - 1s - loss: 0.7523 - acc: 0.2299 - 1s/epoch - 67ms/step\n",
            "Epoch 10/600\n",
            "15/15 - 1s - loss: 0.7414 - acc: 0.2126 - 681ms/epoch - 45ms/step\n",
            "Epoch 11/600\n",
            "15/15 - 1s - loss: 0.7393 - acc: 0.2098 - 667ms/epoch - 44ms/step\n",
            "Epoch 12/600\n",
            "15/15 - 1s - loss: 0.7303 - acc: 0.2385 - 684ms/epoch - 46ms/step\n",
            "Epoch 13/600\n",
            "15/15 - 1s - loss: 0.7166 - acc: 0.2557 - 679ms/epoch - 45ms/step\n",
            "Epoch 14/600\n",
            "15/15 - 1s - loss: 0.7225 - acc: 0.2213 - 671ms/epoch - 45ms/step\n",
            "Epoch 15/600\n",
            "15/15 - 1s - loss: 0.7053 - acc: 0.2471 - 663ms/epoch - 44ms/step\n",
            "Epoch 16/600\n",
            "15/15 - 1s - loss: 0.6994 - acc: 0.2960 - 691ms/epoch - 46ms/step\n",
            "Epoch 17/600\n",
            "15/15 - 1s - loss: 0.6867 - acc: 0.2816 - 692ms/epoch - 46ms/step\n",
            "Epoch 18/600\n",
            "15/15 - 1s - loss: 0.6762 - acc: 0.2902 - 699ms/epoch - 47ms/step\n",
            "Epoch 19/600\n",
            "15/15 - 1s - loss: 0.6722 - acc: 0.2701 - 654ms/epoch - 44ms/step\n",
            "Epoch 20/600\n",
            "15/15 - 1s - loss: 0.6718 - acc: 0.2816 - 669ms/epoch - 45ms/step\n",
            "Epoch 21/600\n",
            "15/15 - 1s - loss: 0.6558 - acc: 0.3046 - 643ms/epoch - 43ms/step\n",
            "Epoch 22/600\n",
            "15/15 - 1s - loss: 0.6452 - acc: 0.3075 - 665ms/epoch - 44ms/step\n",
            "Epoch 23/600\n",
            "15/15 - 1s - loss: 0.6284 - acc: 0.3161 - 733ms/epoch - 49ms/step\n",
            "Epoch 24/600\n",
            "15/15 - 1s - loss: 0.6226 - acc: 0.2989 - 1s/epoch - 68ms/step\n",
            "Epoch 25/600\n",
            "15/15 - 1s - loss: 0.6114 - acc: 0.3161 - 1s/epoch - 78ms/step\n",
            "Epoch 26/600\n",
            "15/15 - 1s - loss: 0.6015 - acc: 0.3333 - 990ms/epoch - 66ms/step\n",
            "Epoch 27/600\n",
            "15/15 - 1s - loss: 0.5818 - acc: 0.3247 - 665ms/epoch - 44ms/step\n",
            "Epoch 28/600\n",
            "15/15 - 1s - loss: 0.5810 - acc: 0.3592 - 656ms/epoch - 44ms/step\n",
            "Epoch 29/600\n",
            "15/15 - 1s - loss: 0.5628 - acc: 0.3621 - 679ms/epoch - 45ms/step\n",
            "Epoch 30/600\n",
            "15/15 - 1s - loss: 0.5510 - acc: 0.3678 - 653ms/epoch - 44ms/step\n",
            "Epoch 31/600\n",
            "15/15 - 1s - loss: 0.5272 - acc: 0.4310 - 661ms/epoch - 44ms/step\n",
            "Epoch 32/600\n",
            "15/15 - 1s - loss: 0.5155 - acc: 0.4080 - 659ms/epoch - 44ms/step\n",
            "Epoch 33/600\n",
            "15/15 - 1s - loss: 0.5151 - acc: 0.4310 - 654ms/epoch - 44ms/step\n",
            "Epoch 34/600\n",
            "15/15 - 1s - loss: 0.4905 - acc: 0.4080 - 665ms/epoch - 44ms/step\n",
            "Epoch 35/600\n",
            "15/15 - 1s - loss: 0.4688 - acc: 0.4569 - 664ms/epoch - 44ms/step\n",
            "Epoch 36/600\n",
            "15/15 - 1s - loss: 0.4636 - acc: 0.4828 - 667ms/epoch - 44ms/step\n",
            "Epoch 37/600\n",
            "15/15 - 1s - loss: 0.4536 - acc: 0.4397 - 692ms/epoch - 46ms/step\n",
            "Epoch 38/600\n",
            "15/15 - 1s - loss: 0.4330 - acc: 0.4885 - 655ms/epoch - 44ms/step\n",
            "Epoch 39/600\n",
            "15/15 - 1s - loss: 0.4233 - acc: 0.5431 - 635ms/epoch - 42ms/step\n",
            "Epoch 40/600\n",
            "15/15 - 1s - loss: 0.4161 - acc: 0.5489 - 669ms/epoch - 45ms/step\n",
            "Epoch 41/600\n",
            "15/15 - 1s - loss: 0.3783 - acc: 0.5431 - 914ms/epoch - 61ms/step\n",
            "Epoch 42/600\n",
            "15/15 - 1s - loss: 0.3761 - acc: 0.5776 - 1s/epoch - 77ms/step\n",
            "Epoch 43/600\n",
            "15/15 - 1s - loss: 0.3720 - acc: 0.5776 - 1s/epoch - 71ms/step\n",
            "Epoch 44/600\n",
            "15/15 - 1s - loss: 0.3475 - acc: 0.5948 - 678ms/epoch - 45ms/step\n",
            "Epoch 45/600\n",
            "15/15 - 1s - loss: 0.3236 - acc: 0.6264 - 683ms/epoch - 46ms/step\n",
            "Epoch 46/600\n",
            "15/15 - 1s - loss: 0.2993 - acc: 0.6437 - 711ms/epoch - 47ms/step\n",
            "Epoch 47/600\n",
            "15/15 - 1s - loss: 0.3046 - acc: 0.6236 - 676ms/epoch - 45ms/step\n",
            "Epoch 48/600\n",
            "15/15 - 1s - loss: 0.2871 - acc: 0.6580 - 667ms/epoch - 44ms/step\n",
            "Epoch 49/600\n",
            "15/15 - 1s - loss: 0.2840 - acc: 0.6638 - 650ms/epoch - 43ms/step\n",
            "Epoch 50/600\n",
            "15/15 - 1s - loss: 0.2648 - acc: 0.6753 - 669ms/epoch - 45ms/step\n",
            "Epoch 51/600\n",
            "15/15 - 1s - loss: 0.2673 - acc: 0.6638 - 652ms/epoch - 43ms/step\n",
            "Epoch 52/600\n",
            "15/15 - 1s - loss: 0.2506 - acc: 0.6868 - 704ms/epoch - 47ms/step\n",
            "Epoch 53/600\n",
            "15/15 - 1s - loss: 0.2445 - acc: 0.7040 - 674ms/epoch - 45ms/step\n",
            "Epoch 54/600\n",
            "15/15 - 1s - loss: 0.2390 - acc: 0.7098 - 658ms/epoch - 44ms/step\n",
            "Epoch 55/600\n",
            "15/15 - 1s - loss: 0.2326 - acc: 0.7126 - 670ms/epoch - 45ms/step\n",
            "Epoch 56/600\n",
            "15/15 - 1s - loss: 0.2143 - acc: 0.7270 - 662ms/epoch - 44ms/step\n",
            "Epoch 57/600\n",
            "15/15 - 1s - loss: 0.2063 - acc: 0.7328 - 664ms/epoch - 44ms/step\n",
            "Epoch 58/600\n",
            "15/15 - 1s - loss: 0.1980 - acc: 0.7644 - 891ms/epoch - 59ms/step\n",
            "Epoch 59/600\n",
            "15/15 - 1s - loss: 0.1871 - acc: 0.7902 - 1s/epoch - 81ms/step\n",
            "Epoch 60/600\n",
            "15/15 - 1s - loss: 0.1795 - acc: 0.8333 - 1s/epoch - 70ms/step\n",
            "Epoch 61/600\n",
            "15/15 - 1s - loss: 0.1828 - acc: 0.7931 - 671ms/epoch - 45ms/step\n",
            "Epoch 62/600\n",
            "15/15 - 1s - loss: 0.1691 - acc: 0.8362 - 665ms/epoch - 44ms/step\n",
            "Epoch 63/600\n",
            "15/15 - 1s - loss: 0.1683 - acc: 0.8132 - 660ms/epoch - 44ms/step\n",
            "Epoch 64/600\n",
            "15/15 - 1s - loss: 0.1658 - acc: 0.8190 - 679ms/epoch - 45ms/step\n",
            "Epoch 65/600\n",
            "15/15 - 1s - loss: 0.1569 - acc: 0.8362 - 660ms/epoch - 44ms/step\n",
            "Epoch 66/600\n",
            "15/15 - 1s - loss: 0.1467 - acc: 0.8218 - 656ms/epoch - 44ms/step\n",
            "Epoch 67/600\n",
            "15/15 - 1s - loss: 0.1461 - acc: 0.8477 - 658ms/epoch - 44ms/step\n",
            "Epoch 68/600\n",
            "15/15 - 1s - loss: 0.1403 - acc: 0.8563 - 673ms/epoch - 45ms/step\n",
            "Epoch 69/600\n",
            "15/15 - 1s - loss: 0.1343 - acc: 0.8793 - 658ms/epoch - 44ms/step\n",
            "Epoch 70/600\n",
            "15/15 - 1s - loss: 0.1267 - acc: 0.8534 - 687ms/epoch - 46ms/step\n",
            "Epoch 71/600\n",
            "15/15 - 1s - loss: 0.1269 - acc: 0.8736 - 658ms/epoch - 44ms/step\n",
            "Epoch 72/600\n",
            "15/15 - 1s - loss: 0.1294 - acc: 0.8707 - 646ms/epoch - 43ms/step\n",
            "Epoch 73/600\n",
            "15/15 - 1s - loss: 0.1204 - acc: 0.8649 - 679ms/epoch - 45ms/step\n",
            "Epoch 74/600\n",
            "15/15 - 1s - loss: 0.1177 - acc: 0.8793 - 676ms/epoch - 45ms/step\n",
            "Epoch 75/600\n",
            "15/15 - 1s - loss: 0.1241 - acc: 0.8908 - 811ms/epoch - 54ms/step\n",
            "Epoch 76/600\n",
            "15/15 - 1s - loss: 0.1178 - acc: 0.8908 - 1s/epoch - 77ms/step\n",
            "Epoch 77/600\n",
            "15/15 - 1s - loss: 0.1062 - acc: 0.9052 - 1s/epoch - 77ms/step\n",
            "Epoch 78/600\n",
            "15/15 - 1s - loss: 0.1018 - acc: 0.8764 - 650ms/epoch - 43ms/step\n",
            "Epoch 79/600\n",
            "15/15 - 1s - loss: 0.1061 - acc: 0.9138 - 682ms/epoch - 45ms/step\n",
            "Epoch 80/600\n",
            "15/15 - 1s - loss: 0.0997 - acc: 0.8879 - 652ms/epoch - 43ms/step\n",
            "Epoch 81/600\n",
            "15/15 - 1s - loss: 0.1003 - acc: 0.9080 - 658ms/epoch - 44ms/step\n",
            "Epoch 82/600\n",
            "15/15 - 1s - loss: 0.0966 - acc: 0.8937 - 669ms/epoch - 45ms/step\n",
            "Epoch 83/600\n",
            "15/15 - 1s - loss: 0.0964 - acc: 0.9167 - 695ms/epoch - 46ms/step\n",
            "Epoch 84/600\n",
            "15/15 - 1s - loss: 0.0978 - acc: 0.8879 - 697ms/epoch - 46ms/step\n",
            "Epoch 85/600\n",
            "15/15 - 1s - loss: 0.0955 - acc: 0.9109 - 654ms/epoch - 44ms/step\n",
            "Epoch 86/600\n",
            "15/15 - 1s - loss: 0.0939 - acc: 0.8879 - 699ms/epoch - 47ms/step\n",
            "Epoch 87/600\n",
            "15/15 - 1s - loss: 0.0965 - acc: 0.8937 - 651ms/epoch - 43ms/step\n",
            "Epoch 88/600\n",
            "15/15 - 1s - loss: 0.0924 - acc: 0.9052 - 663ms/epoch - 44ms/step\n",
            "Epoch 89/600\n",
            "15/15 - 1s - loss: 0.0918 - acc: 0.9052 - 668ms/epoch - 45ms/step\n",
            "Epoch 90/600\n",
            "15/15 - 1s - loss: 0.0892 - acc: 0.9167 - 641ms/epoch - 43ms/step\n",
            "Epoch 91/600\n",
            "15/15 - 1s - loss: 0.0888 - acc: 0.9224 - 664ms/epoch - 44ms/step\n",
            "Epoch 92/600\n",
            "15/15 - 1s - loss: 0.0833 - acc: 0.9023 - 730ms/epoch - 49ms/step\n",
            "Epoch 93/600\n",
            "15/15 - 1s - loss: 0.0793 - acc: 0.9339 - 1s/epoch - 78ms/step\n",
            "Epoch 94/600\n",
            "15/15 - 1s - loss: 0.0824 - acc: 0.9138 - 1s/epoch - 80ms/step\n",
            "Epoch 95/600\n",
            "15/15 - 1s - loss: 0.0791 - acc: 0.9310 - 725ms/epoch - 48ms/step\n",
            "Epoch 96/600\n",
            "15/15 - 1s - loss: 0.0800 - acc: 0.9138 - 644ms/epoch - 43ms/step\n",
            "Epoch 97/600\n",
            "15/15 - 1s - loss: 0.0762 - acc: 0.9282 - 659ms/epoch - 44ms/step\n",
            "Epoch 98/600\n",
            "15/15 - 1s - loss: 0.0780 - acc: 0.9282 - 655ms/epoch - 44ms/step\n",
            "Epoch 99/600\n",
            "15/15 - 1s - loss: 0.0770 - acc: 0.9167 - 668ms/epoch - 45ms/step\n",
            "Epoch 100/600\n",
            "15/15 - 1s - loss: 0.0770 - acc: 0.9224 - 678ms/epoch - 45ms/step\n",
            "Epoch 101/600\n",
            "15/15 - 1s - loss: 0.0748 - acc: 0.9195 - 672ms/epoch - 45ms/step\n",
            "Epoch 102/600\n",
            "15/15 - 1s - loss: 0.0734 - acc: 0.9224 - 657ms/epoch - 44ms/step\n",
            "Epoch 103/600\n",
            "15/15 - 1s - loss: 0.0713 - acc: 0.9397 - 673ms/epoch - 45ms/step\n",
            "Epoch 104/600\n",
            "15/15 - 1s - loss: 0.0720 - acc: 0.9195 - 652ms/epoch - 43ms/step\n",
            "Epoch 105/600\n",
            "15/15 - 1s - loss: 0.0727 - acc: 0.9195 - 656ms/epoch - 44ms/step\n",
            "Epoch 106/600\n",
            "15/15 - 1s - loss: 0.0726 - acc: 0.9109 - 672ms/epoch - 45ms/step\n",
            "Epoch 107/600\n",
            "15/15 - 1s - loss: 0.0702 - acc: 0.9425 - 663ms/epoch - 44ms/step\n",
            "Epoch 108/600\n",
            "15/15 - 1s - loss: 0.0661 - acc: 0.9253 - 690ms/epoch - 46ms/step\n",
            "Epoch 109/600\n",
            "15/15 - 1s - loss: 0.0662 - acc: 0.9397 - 656ms/epoch - 44ms/step\n",
            "Epoch 110/600\n",
            "15/15 - 1s - loss: 0.0714 - acc: 0.9339 - 1s/epoch - 75ms/step\n",
            "Epoch 111/600\n",
            "15/15 - 1s - loss: 0.0675 - acc: 0.9425 - 1s/epoch - 83ms/step\n",
            "Epoch 112/600\n",
            "15/15 - 1s - loss: 0.0661 - acc: 0.9397 - 790ms/epoch - 53ms/step\n",
            "Epoch 113/600\n",
            "15/15 - 1s - loss: 0.0686 - acc: 0.9569 - 648ms/epoch - 43ms/step\n",
            "Epoch 114/600\n",
            "15/15 - 1s - loss: 0.0659 - acc: 0.9224 - 674ms/epoch - 45ms/step\n",
            "Epoch 115/600\n",
            "15/15 - 1s - loss: 0.0645 - acc: 0.9425 - 681ms/epoch - 45ms/step\n",
            "Epoch 116/600\n",
            "15/15 - 1s - loss: 0.0639 - acc: 0.9253 - 670ms/epoch - 45ms/step\n",
            "Epoch 117/600\n",
            "15/15 - 1s - loss: 0.0617 - acc: 0.9598 - 662ms/epoch - 44ms/step\n",
            "Epoch 118/600\n",
            "15/15 - 1s - loss: 0.0591 - acc: 0.9368 - 712ms/epoch - 47ms/step\n",
            "Epoch 119/600\n",
            "15/15 - 1s - loss: 0.0637 - acc: 0.9454 - 666ms/epoch - 44ms/step\n",
            "Epoch 120/600\n",
            "15/15 - 1s - loss: 0.0613 - acc: 0.9397 - 670ms/epoch - 45ms/step\n",
            "Epoch 121/600\n",
            "15/15 - 1s - loss: 0.0622 - acc: 0.9511 - 698ms/epoch - 47ms/step\n",
            "Epoch 122/600\n",
            "15/15 - 1s - loss: 0.0604 - acc: 0.9368 - 667ms/epoch - 44ms/step\n",
            "Epoch 123/600\n",
            "15/15 - 1s - loss: 0.0604 - acc: 0.9224 - 697ms/epoch - 46ms/step\n",
            "Epoch 124/600\n",
            "15/15 - 1s - loss: 0.0606 - acc: 0.9511 - 644ms/epoch - 43ms/step\n",
            "Epoch 125/600\n",
            "15/15 - 1s - loss: 0.0597 - acc: 0.9483 - 646ms/epoch - 43ms/step\n",
            "Epoch 126/600\n",
            "15/15 - 1s - loss: 0.0594 - acc: 0.9368 - 667ms/epoch - 44ms/step\n",
            "Epoch 127/600\n",
            "15/15 - 1s - loss: 0.0630 - acc: 0.9425 - 1s/epoch - 75ms/step\n",
            "Epoch 128/600\n",
            "15/15 - 1s - loss: 0.0587 - acc: 0.9483 - 1s/epoch - 77ms/step\n",
            "Epoch 129/600\n",
            "15/15 - 1s - loss: 0.0604 - acc: 0.9483 - 831ms/epoch - 55ms/step\n",
            "Epoch 130/600\n",
            "15/15 - 1s - loss: 0.0593 - acc: 0.9425 - 659ms/epoch - 44ms/step\n",
            "Epoch 131/600\n",
            "15/15 - 1s - loss: 0.0588 - acc: 0.9339 - 649ms/epoch - 43ms/step\n",
            "Epoch 132/600\n",
            "15/15 - 1s - loss: 0.0581 - acc: 0.9425 - 672ms/epoch - 45ms/step\n",
            "Epoch 133/600\n",
            "15/15 - 1s - loss: 0.0560 - acc: 0.9569 - 659ms/epoch - 44ms/step\n",
            "Epoch 134/600\n",
            "15/15 - 1s - loss: 0.0564 - acc: 0.9483 - 660ms/epoch - 44ms/step\n",
            "Epoch 135/600\n",
            "15/15 - 1s - loss: 0.0594 - acc: 0.9195 - 664ms/epoch - 44ms/step\n",
            "Epoch 136/600\n",
            "15/15 - 1s - loss: 0.0561 - acc: 0.9483 - 682ms/epoch - 45ms/step\n",
            "Epoch 137/600\n",
            "15/15 - 1s - loss: 0.0570 - acc: 0.9454 - 660ms/epoch - 44ms/step\n",
            "Epoch 138/600\n",
            "15/15 - 1s - loss: 0.0557 - acc: 0.9483 - 678ms/epoch - 45ms/step\n",
            "Epoch 139/600\n",
            "15/15 - 1s - loss: 0.0530 - acc: 0.9655 - 675ms/epoch - 45ms/step\n",
            "Epoch 140/600\n",
            "15/15 - 1s - loss: 0.0526 - acc: 0.9425 - 661ms/epoch - 44ms/step\n",
            "Epoch 141/600\n",
            "15/15 - 1s - loss: 0.0516 - acc: 0.9684 - 667ms/epoch - 44ms/step\n",
            "Epoch 142/600\n",
            "15/15 - 1s - loss: 0.0531 - acc: 0.9397 - 658ms/epoch - 44ms/step\n",
            "Epoch 143/600\n",
            "15/15 - 1s - loss: 0.0504 - acc: 0.9425 - 661ms/epoch - 44ms/step\n",
            "Epoch 144/600\n",
            "15/15 - 1s - loss: 0.0554 - acc: 0.9569 - 976ms/epoch - 65ms/step\n",
            "Epoch 145/600\n",
            "15/15 - 1s - loss: 0.0550 - acc: 0.9540 - 1s/epoch - 77ms/step\n",
            "Epoch 146/600\n",
            "15/15 - 1s - loss: 0.0549 - acc: 0.9368 - 980ms/epoch - 65ms/step\n",
            "Epoch 147/600\n",
            "15/15 - 1s - loss: 0.0538 - acc: 0.9598 - 654ms/epoch - 44ms/step\n",
            "Epoch 148/600\n",
            "15/15 - 1s - loss: 0.0531 - acc: 0.9511 - 659ms/epoch - 44ms/step\n",
            "Epoch 149/600\n",
            "15/15 - 1s - loss: 0.0550 - acc: 0.9511 - 650ms/epoch - 43ms/step\n",
            "Epoch 150/600\n",
            "15/15 - 1s - loss: 0.0535 - acc: 0.9339 - 672ms/epoch - 45ms/step\n",
            "Epoch 151/600\n",
            "15/15 - 1s - loss: 0.0517 - acc: 0.9511 - 672ms/epoch - 45ms/step\n",
            "Epoch 152/600\n",
            "15/15 - 1s - loss: 0.0490 - acc: 0.9684 - 684ms/epoch - 46ms/step\n",
            "Epoch 153/600\n",
            "15/15 - 1s - loss: 0.0483 - acc: 0.9626 - 675ms/epoch - 45ms/step\n",
            "Epoch 154/600\n",
            "15/15 - 1s - loss: 0.0479 - acc: 0.9598 - 702ms/epoch - 47ms/step\n",
            "Epoch 155/600\n",
            "15/15 - 1s - loss: 0.0509 - acc: 0.9339 - 676ms/epoch - 45ms/step\n",
            "Epoch 156/600\n",
            "15/15 - 1s - loss: 0.0475 - acc: 0.9540 - 676ms/epoch - 45ms/step\n",
            "Epoch 157/600\n",
            "15/15 - 1s - loss: 0.0503 - acc: 0.9655 - 704ms/epoch - 47ms/step\n",
            "Epoch 158/600\n",
            "15/15 - 1s - loss: 0.0506 - acc: 0.9511 - 660ms/epoch - 44ms/step\n",
            "Epoch 159/600\n",
            "15/15 - 1s - loss: 0.0500 - acc: 0.9511 - 701ms/epoch - 47ms/step\n",
            "Epoch 160/600\n",
            "15/15 - 1s - loss: 0.0522 - acc: 0.9397 - 663ms/epoch - 44ms/step\n",
            "Epoch 161/600\n",
            "15/15 - 1s - loss: 0.0536 - acc: 0.9425 - 965ms/epoch - 64ms/step\n",
            "Epoch 162/600\n",
            "15/15 - 1s - loss: 0.0530 - acc: 0.9540 - 1s/epoch - 77ms/step\n",
            "Epoch 163/600\n",
            "15/15 - 1s - loss: 0.0511 - acc: 0.9483 - 1s/epoch - 68ms/step\n",
            "Epoch 164/600\n",
            "15/15 - 1s - loss: 0.0504 - acc: 0.9483 - 667ms/epoch - 44ms/step\n",
            "Epoch 165/600\n",
            "15/15 - 1s - loss: 0.0468 - acc: 0.9713 - 650ms/epoch - 43ms/step\n",
            "Epoch 166/600\n",
            "15/15 - 1s - loss: 0.0468 - acc: 0.9569 - 671ms/epoch - 45ms/step\n",
            "Epoch 167/600\n",
            "15/15 - 1s - loss: 0.0460 - acc: 0.9569 - 647ms/epoch - 43ms/step\n",
            "Epoch 168/600\n",
            "15/15 - 1s - loss: 0.0461 - acc: 0.9540 - 659ms/epoch - 44ms/step\n",
            "Epoch 169/600\n",
            "15/15 - 1s - loss: 0.0475 - acc: 0.9741 - 668ms/epoch - 45ms/step\n",
            "Epoch 170/600\n",
            "15/15 - 1s - loss: 0.0469 - acc: 0.9626 - 650ms/epoch - 43ms/step\n",
            "Epoch 171/600\n",
            "15/15 - 1s - loss: 0.0479 - acc: 0.9655 - 665ms/epoch - 44ms/step\n",
            "Epoch 172/600\n",
            "15/15 - 1s - loss: 0.0465 - acc: 0.9626 - 663ms/epoch - 44ms/step\n",
            "Epoch 173/600\n",
            "15/15 - 1s - loss: 0.0473 - acc: 0.9511 - 655ms/epoch - 44ms/step\n",
            "Epoch 174/600\n",
            "15/15 - 1s - loss: 0.0463 - acc: 0.9626 - 677ms/epoch - 45ms/step\n",
            "Epoch 175/600\n",
            "15/15 - 1s - loss: 0.0464 - acc: 0.9713 - 698ms/epoch - 47ms/step\n",
            "Epoch 176/600\n",
            "15/15 - 1s - loss: 0.0473 - acc: 0.9339 - 659ms/epoch - 44ms/step\n",
            "Epoch 177/600\n",
            "15/15 - 1s - loss: 0.0474 - acc: 0.9655 - 679ms/epoch - 45ms/step\n",
            "Epoch 178/600\n",
            "15/15 - 1s - loss: 0.0459 - acc: 0.9598 - 853ms/epoch - 57ms/step\n",
            "Epoch 179/600\n",
            "15/15 - 1s - loss: 0.0446 - acc: 0.9741 - 1s/epoch - 78ms/step\n",
            "Epoch 180/600\n",
            "15/15 - 1s - loss: 0.0457 - acc: 0.9511 - 1s/epoch - 74ms/step\n",
            "Epoch 181/600\n",
            "15/15 - 1s - loss: 0.0453 - acc: 0.9483 - 659ms/epoch - 44ms/step\n",
            "Epoch 182/600\n",
            "15/15 - 1s - loss: 0.0467 - acc: 0.9626 - 663ms/epoch - 44ms/step\n",
            "Epoch 183/600\n",
            "15/15 - 1s - loss: 0.0456 - acc: 0.9511 - 676ms/epoch - 45ms/step\n",
            "Epoch 184/600\n",
            "15/15 - 1s - loss: 0.0469 - acc: 0.9626 - 652ms/epoch - 43ms/step\n",
            "Epoch 185/600\n",
            "15/15 - 1s - loss: 0.0457 - acc: 0.9598 - 711ms/epoch - 47ms/step\n",
            "Epoch 186/600\n",
            "15/15 - 1s - loss: 0.0427 - acc: 0.9511 - 654ms/epoch - 44ms/step\n",
            "Epoch 187/600\n",
            "15/15 - 1s - loss: 0.0443 - acc: 0.9483 - 644ms/epoch - 43ms/step\n",
            "Epoch 188/600\n",
            "15/15 - 1s - loss: 0.0436 - acc: 0.9598 - 687ms/epoch - 46ms/step\n",
            "Epoch 189/600\n",
            "15/15 - 1s - loss: 0.0425 - acc: 0.9713 - 716ms/epoch - 48ms/step\n",
            "Epoch 190/600\n",
            "15/15 - 1s - loss: 0.0461 - acc: 0.9713 - 668ms/epoch - 45ms/step\n",
            "Epoch 191/600\n",
            "15/15 - 1s - loss: 0.0436 - acc: 0.9540 - 667ms/epoch - 44ms/step\n",
            "Epoch 192/600\n",
            "15/15 - 1s - loss: 0.0453 - acc: 0.9569 - 707ms/epoch - 47ms/step\n",
            "Epoch 193/600\n",
            "15/15 - 1s - loss: 0.0428 - acc: 0.9799 - 665ms/epoch - 44ms/step\n",
            "Epoch 194/600\n",
            "15/15 - 1s - loss: 0.0433 - acc: 0.9799 - 675ms/epoch - 45ms/step\n",
            "Epoch 195/600\n",
            "15/15 - 1s - loss: 0.0438 - acc: 0.9569 - 868ms/epoch - 58ms/step\n",
            "Epoch 196/600\n",
            "15/15 - 1s - loss: 0.0429 - acc: 0.9598 - 1s/epoch - 76ms/step\n",
            "Epoch 197/600\n",
            "15/15 - 1s - loss: 0.0407 - acc: 0.9569 - 1s/epoch - 74ms/step\n",
            "Epoch 198/600\n",
            "15/15 - 1s - loss: 0.0416 - acc: 0.9684 - 681ms/epoch - 45ms/step\n",
            "Epoch 199/600\n",
            "15/15 - 1s - loss: 0.0421 - acc: 0.9713 - 684ms/epoch - 46ms/step\n",
            "Epoch 200/600\n",
            "15/15 - 1s - loss: 0.0413 - acc: 0.9741 - 650ms/epoch - 43ms/step\n",
            "Epoch 201/600\n",
            "15/15 - 1s - loss: 0.0407 - acc: 0.9626 - 670ms/epoch - 45ms/step\n",
            "Epoch 202/600\n",
            "15/15 - 1s - loss: 0.0411 - acc: 0.9511 - 641ms/epoch - 43ms/step\n",
            "Epoch 203/600\n",
            "15/15 - 1s - loss: 0.0415 - acc: 0.9684 - 672ms/epoch - 45ms/step\n",
            "Epoch 204/600\n",
            "15/15 - 1s - loss: 0.0424 - acc: 0.9569 - 683ms/epoch - 46ms/step\n",
            "Epoch 205/600\n",
            "15/15 - 1s - loss: 0.0390 - acc: 0.9626 - 671ms/epoch - 45ms/step\n",
            "Epoch 206/600\n",
            "15/15 - 1s - loss: 0.0384 - acc: 0.9914 - 666ms/epoch - 44ms/step\n",
            "Epoch 207/600\n",
            "15/15 - 1s - loss: 0.0399 - acc: 0.9598 - 684ms/epoch - 46ms/step\n",
            "Epoch 208/600\n",
            "15/15 - 1s - loss: 0.0412 - acc: 0.9626 - 644ms/epoch - 43ms/step\n",
            "Epoch 209/600\n",
            "15/15 - 1s - loss: 0.0420 - acc: 0.9598 - 666ms/epoch - 44ms/step\n",
            "Epoch 210/600\n",
            "15/15 - 1s - loss: 0.0414 - acc: 0.9598 - 681ms/epoch - 45ms/step\n",
            "Epoch 211/600\n",
            "15/15 - 1s - loss: 0.0400 - acc: 0.9713 - 650ms/epoch - 43ms/step\n",
            "Epoch 212/600\n",
            "15/15 - 1s - loss: 0.0390 - acc: 0.9511 - 814ms/epoch - 54ms/step\n",
            "Epoch 213/600\n",
            "15/15 - 1s - loss: 0.0402 - acc: 0.9655 - 1s/epoch - 78ms/step\n",
            "Epoch 214/600\n",
            "15/15 - 1s - loss: 0.0396 - acc: 0.9540 - 1s/epoch - 77ms/step\n",
            "Epoch 215/600\n",
            "15/15 - 1s - loss: 0.0401 - acc: 0.9569 - 655ms/epoch - 44ms/step\n",
            "Epoch 216/600\n",
            "15/15 - 1s - loss: 0.0390 - acc: 0.9684 - 662ms/epoch - 44ms/step\n",
            "Epoch 217/600\n",
            "15/15 - 1s - loss: 0.0404 - acc: 0.9569 - 652ms/epoch - 43ms/step\n",
            "Epoch 218/600\n",
            "15/15 - 1s - loss: 0.0365 - acc: 0.9799 - 664ms/epoch - 44ms/step\n",
            "Epoch 219/600\n",
            "15/15 - 1s - loss: 0.0400 - acc: 0.9655 - 682ms/epoch - 45ms/step\n",
            "Epoch 220/600\n",
            "15/15 - 1s - loss: 0.0421 - acc: 0.9626 - 657ms/epoch - 44ms/step\n",
            "Epoch 221/600\n",
            "15/15 - 1s - loss: 0.0401 - acc: 0.9569 - 675ms/epoch - 45ms/step\n",
            "Epoch 222/600\n",
            "15/15 - 1s - loss: 0.0394 - acc: 0.9598 - 677ms/epoch - 45ms/step\n",
            "Epoch 223/600\n",
            "15/15 - 1s - loss: 0.0389 - acc: 0.9540 - 651ms/epoch - 43ms/step\n",
            "Epoch 224/600\n",
            "15/15 - 1s - loss: 0.0369 - acc: 0.9569 - 680ms/epoch - 45ms/step\n",
            "Epoch 225/600\n",
            "15/15 - 1s - loss: 0.0385 - acc: 0.9655 - 679ms/epoch - 45ms/step\n",
            "Epoch 226/600\n",
            "15/15 - 1s - loss: 0.0376 - acc: 0.9540 - 646ms/epoch - 43ms/step\n",
            "Epoch 227/600\n",
            "15/15 - 1s - loss: 0.0388 - acc: 0.9684 - 717ms/epoch - 48ms/step\n",
            "Epoch 228/600\n",
            "15/15 - 1s - loss: 0.0367 - acc: 0.9799 - 674ms/epoch - 45ms/step\n",
            "Epoch 229/600\n",
            "15/15 - 1s - loss: 0.0396 - acc: 0.9684 - 740ms/epoch - 49ms/step\n",
            "Epoch 230/600\n",
            "15/15 - 1s - loss: 0.0372 - acc: 0.9569 - 1s/epoch - 77ms/step\n",
            "Epoch 231/600\n",
            "15/15 - 1s - loss: 0.0377 - acc: 0.9684 - 1s/epoch - 78ms/step\n",
            "Epoch 232/600\n",
            "15/15 - 1s - loss: 0.0384 - acc: 0.9684 - 734ms/epoch - 49ms/step\n",
            "Epoch 233/600\n",
            "15/15 - 1s - loss: 0.0390 - acc: 0.9626 - 678ms/epoch - 45ms/step\n",
            "Epoch 234/600\n",
            "15/15 - 1s - loss: 0.0387 - acc: 0.9713 - 675ms/epoch - 45ms/step\n",
            "Epoch 235/600\n",
            "15/15 - 1s - loss: 0.0385 - acc: 0.9569 - 671ms/epoch - 45ms/step\n",
            "Epoch 236/600\n",
            "15/15 - 1s - loss: 0.0384 - acc: 0.9713 - 684ms/epoch - 46ms/step\n",
            "Epoch 237/600\n",
            "15/15 - 1s - loss: 0.0388 - acc: 0.9483 - 679ms/epoch - 45ms/step\n",
            "Epoch 238/600\n",
            "15/15 - 1s - loss: 0.0372 - acc: 0.9828 - 669ms/epoch - 45ms/step\n",
            "Epoch 239/600\n",
            "15/15 - 1s - loss: 0.0373 - acc: 0.9741 - 680ms/epoch - 45ms/step\n",
            "Epoch 240/600\n",
            "15/15 - 1s - loss: 0.0359 - acc: 0.9569 - 690ms/epoch - 46ms/step\n",
            "Epoch 241/600\n",
            "15/15 - 1s - loss: 0.0354 - acc: 0.9626 - 672ms/epoch - 45ms/step\n",
            "Epoch 242/600\n",
            "15/15 - 1s - loss: 0.0366 - acc: 0.9684 - 665ms/epoch - 44ms/step\n",
            "Epoch 243/600\n",
            "15/15 - 1s - loss: 0.0392 - acc: 0.9684 - 683ms/epoch - 46ms/step\n",
            "Epoch 244/600\n",
            "15/15 - 1s - loss: 0.0371 - acc: 0.9713 - 658ms/epoch - 44ms/step\n",
            "Epoch 245/600\n",
            "15/15 - 1s - loss: 0.0377 - acc: 0.9684 - 669ms/epoch - 45ms/step\n",
            "Epoch 246/600\n",
            "15/15 - 1s - loss: 0.0382 - acc: 0.9626 - 734ms/epoch - 49ms/step\n",
            "Epoch 247/600\n",
            "15/15 - 1s - loss: 0.0376 - acc: 0.9741 - 1s/epoch - 79ms/step\n",
            "Epoch 248/600\n",
            "15/15 - 1s - loss: 0.0363 - acc: 0.9770 - 1s/epoch - 77ms/step\n",
            "Epoch 249/600\n",
            "15/15 - 1s - loss: 0.0350 - acc: 0.9684 - 727ms/epoch - 48ms/step\n",
            "Epoch 250/600\n",
            "15/15 - 1s - loss: 0.0358 - acc: 0.9770 - 658ms/epoch - 44ms/step\n",
            "Epoch 251/600\n",
            "15/15 - 1s - loss: 0.0350 - acc: 0.9598 - 699ms/epoch - 47ms/step\n",
            "Epoch 252/600\n",
            "15/15 - 1s - loss: 0.0364 - acc: 0.9799 - 651ms/epoch - 43ms/step\n",
            "Epoch 253/600\n",
            "15/15 - 1s - loss: 0.0354 - acc: 0.9598 - 664ms/epoch - 44ms/step\n",
            "Epoch 254/600\n",
            "15/15 - 1s - loss: 0.0355 - acc: 0.9770 - 682ms/epoch - 45ms/step\n",
            "Epoch 255/600\n",
            "15/15 - 1s - loss: 0.0359 - acc: 0.9655 - 673ms/epoch - 45ms/step\n",
            "Epoch 256/600\n",
            "15/15 - 1s - loss: 0.0355 - acc: 0.9626 - 666ms/epoch - 44ms/step\n",
            "Epoch 257/600\n",
            "15/15 - 1s - loss: 0.0364 - acc: 0.9713 - 671ms/epoch - 45ms/step\n",
            "Epoch 258/600\n",
            "15/15 - 1s - loss: 0.0351 - acc: 0.9770 - 663ms/epoch - 44ms/step\n",
            "Epoch 259/600\n",
            "15/15 - 1s - loss: 0.0369 - acc: 0.9626 - 669ms/epoch - 45ms/step\n",
            "Epoch 260/600\n",
            "15/15 - 1s - loss: 0.0369 - acc: 0.9569 - 675ms/epoch - 45ms/step\n",
            "Epoch 261/600\n",
            "15/15 - 1s - loss: 0.0353 - acc: 0.9626 - 687ms/epoch - 46ms/step\n",
            "Epoch 262/600\n",
            "15/15 - 1s - loss: 0.0352 - acc: 0.9828 - 691ms/epoch - 46ms/step\n",
            "Epoch 263/600\n",
            "15/15 - 1s - loss: 0.0353 - acc: 0.9741 - 770ms/epoch - 51ms/step\n",
            "Epoch 264/600\n",
            "15/15 - 1s - loss: 0.0349 - acc: 0.9713 - 1s/epoch - 78ms/step\n",
            "Epoch 265/600\n",
            "15/15 - 1s - loss: 0.0352 - acc: 0.9598 - 1s/epoch - 79ms/step\n",
            "Epoch 266/600\n",
            "15/15 - 1s - loss: 0.0369 - acc: 0.9655 - 684ms/epoch - 46ms/step\n",
            "Epoch 267/600\n",
            "15/15 - 1s - loss: 0.0357 - acc: 0.9684 - 684ms/epoch - 46ms/step\n",
            "Epoch 268/600\n",
            "15/15 - 1s - loss: 0.0356 - acc: 0.9626 - 662ms/epoch - 44ms/step\n",
            "Epoch 269/600\n",
            "15/15 - 1s - loss: 0.0349 - acc: 0.9770 - 656ms/epoch - 44ms/step\n",
            "Epoch 270/600\n",
            "15/15 - 1s - loss: 0.0344 - acc: 0.9598 - 666ms/epoch - 44ms/step\n",
            "Epoch 271/600\n",
            "15/15 - 1s - loss: 0.0339 - acc: 0.9655 - 666ms/epoch - 44ms/step\n",
            "Epoch 272/600\n",
            "15/15 - 1s - loss: 0.0349 - acc: 0.9598 - 687ms/epoch - 46ms/step\n",
            "Epoch 273/600\n",
            "15/15 - 1s - loss: 0.0341 - acc: 0.9655 - 674ms/epoch - 45ms/step\n",
            "Epoch 274/600\n",
            "15/15 - 1s - loss: 0.0347 - acc: 0.9655 - 653ms/epoch - 44ms/step\n",
            "Epoch 275/600\n",
            "15/15 - 1s - loss: 0.0349 - acc: 0.9540 - 676ms/epoch - 45ms/step\n",
            "Epoch 276/600\n",
            "15/15 - 1s - loss: 0.0358 - acc: 0.9684 - 674ms/epoch - 45ms/step\n",
            "Epoch 277/600\n",
            "15/15 - 1s - loss: 0.0351 - acc: 0.9626 - 671ms/epoch - 45ms/step\n",
            "Epoch 278/600\n",
            "15/15 - 1s - loss: 0.0352 - acc: 0.9684 - 676ms/epoch - 45ms/step\n",
            "Epoch 279/600\n",
            "15/15 - 1s - loss: 0.0355 - acc: 0.9713 - 672ms/epoch - 45ms/step\n",
            "Epoch 280/600\n",
            "15/15 - 1s - loss: 0.0345 - acc: 0.9626 - 737ms/epoch - 49ms/step\n",
            "Epoch 281/600\n",
            "15/15 - 1s - loss: 0.0333 - acc: 0.9713 - 1s/epoch - 79ms/step\n",
            "Epoch 282/600\n",
            "15/15 - 1s - loss: 0.0332 - acc: 0.9713 - 1s/epoch - 80ms/step\n",
            "Epoch 283/600\n",
            "15/15 - 1s - loss: 0.0325 - acc: 0.9655 - 700ms/epoch - 47ms/step\n",
            "Epoch 284/600\n",
            "15/15 - 1s - loss: 0.0326 - acc: 0.9713 - 648ms/epoch - 43ms/step\n",
            "Epoch 285/600\n",
            "15/15 - 1s - loss: 0.0344 - acc: 0.9569 - 671ms/epoch - 45ms/step\n",
            "Epoch 286/600\n",
            "15/15 - 1s - loss: 0.0330 - acc: 0.9713 - 667ms/epoch - 44ms/step\n",
            "Epoch 287/600\n",
            "15/15 - 1s - loss: 0.0325 - acc: 0.9799 - 659ms/epoch - 44ms/step\n",
            "Epoch 288/600\n",
            "15/15 - 1s - loss: 0.0345 - acc: 0.9655 - 657ms/epoch - 44ms/step\n",
            "Epoch 289/600\n",
            "15/15 - 1s - loss: 0.0335 - acc: 0.9598 - 658ms/epoch - 44ms/step\n",
            "Epoch 290/600\n",
            "15/15 - 1s - loss: 0.0327 - acc: 0.9713 - 656ms/epoch - 44ms/step\n",
            "Epoch 291/600\n",
            "15/15 - 1s - loss: 0.0333 - acc: 0.9741 - 660ms/epoch - 44ms/step\n",
            "Epoch 292/600\n",
            "15/15 - 1s - loss: 0.0337 - acc: 0.9626 - 640ms/epoch - 43ms/step\n",
            "Epoch 293/600\n",
            "15/15 - 1s - loss: 0.0380 - acc: 0.9828 - 655ms/epoch - 44ms/step\n",
            "Epoch 294/600\n",
            "15/15 - 1s - loss: 0.0497 - acc: 0.9598 - 693ms/epoch - 46ms/step\n",
            "Epoch 295/600\n",
            "15/15 - 1s - loss: 0.0473 - acc: 0.9569 - 658ms/epoch - 44ms/step\n",
            "Epoch 296/600\n",
            "15/15 - 1s - loss: 0.0506 - acc: 0.9655 - 666ms/epoch - 44ms/step\n",
            "Epoch 297/600\n",
            "15/15 - 1s - loss: 0.0490 - acc: 0.9454 - 698ms/epoch - 47ms/step\n",
            "Epoch 298/600\n",
            "15/15 - 1s - loss: 0.0433 - acc: 0.9454 - 1s/epoch - 75ms/step\n",
            "Epoch 299/600\n",
            "15/15 - 1s - loss: 0.0401 - acc: 0.9626 - 1s/epoch - 77ms/step\n",
            "Epoch 300/600\n",
            "15/15 - 1s - loss: 0.0452 - acc: 0.9540 - 849ms/epoch - 57ms/step\n",
            "Epoch 301/600\n",
            "15/15 - 1s - loss: 0.0467 - acc: 0.9598 - 667ms/epoch - 44ms/step\n",
            "Epoch 302/600\n",
            "15/15 - 1s - loss: 0.0436 - acc: 0.9569 - 665ms/epoch - 44ms/step\n",
            "Epoch 303/600\n",
            "15/15 - 1s - loss: 0.0399 - acc: 0.9655 - 654ms/epoch - 44ms/step\n",
            "Epoch 304/600\n",
            "15/15 - 1s - loss: 0.0392 - acc: 0.9684 - 667ms/epoch - 44ms/step\n",
            "Epoch 305/600\n",
            "15/15 - 1s - loss: 0.0405 - acc: 0.9569 - 691ms/epoch - 46ms/step\n",
            "Epoch 306/600\n",
            "15/15 - 1s - loss: 0.0590 - acc: 0.9195 - 711ms/epoch - 47ms/step\n",
            "Epoch 306: early stopping\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(history.history['loss'])\n",
        "plt.legend(['train_loss'])\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 430
        },
        "id": "5xP9W6gJK5vb",
        "outputId": "0f0bb66e-6242-4b31-fd0b-b3f52c507d59"
      },
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Prediction basée sur les 12 derniers tirages\n",
        "last_twelve = df.tail(window_length) # on recupere les derniers tirages\n",
        "scaler = StandardScaler().fit(df.values)\n",
        "scaled_to_predict = scaler.transform(last_twelve)\n",
        "scaled_predicted_output_1 = model.predict(np.array([scaled_to_predict]), )"
      ],
      "metadata": {
        "id": "BMdRVBeQLNtB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5f3a73b3-8d3c-4c4c-eb95-40493063e347"
      },
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:432: UserWarning: X has feature names, but StandardScaler was fitted without feature names\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 1s 1s/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#prediction\n",
        "tom = df.tail(window_length).iloc[:,0:8] # \n",
        "#print(tom)\n",
        "scaler = StandardScaler().fit(df.iloc[:,0:8])\n",
        "scaled_to_predict = scaler.transform(tom)\n",
        "#print(scaled_to_predict)\n",
        "print(scaler.inverse_transform(scaled_predicted_output_1).astype(int)[:])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GbQ2dXKwLmdX",
        "outputId": "a8f4c792-f084-4ca4-b1fe-67bf84a8bd73"
      },
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[15 17 30 31 33 40 48 13]]\n"
          ]
        }
      ]
    }
  ]
}